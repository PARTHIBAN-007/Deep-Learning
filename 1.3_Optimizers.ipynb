{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138e46f1",
   "metadata": {
    "papermill": {
     "duration": 0.005355,
     "end_time": "2024-09-27T14:10:34.060442",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.055087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\">Optimizers</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70530e7b",
   "metadata": {},
   "source": [
    "<div style =\"font-size:25px; padding:10px; border-radius:15px; background-color:#fffafa; color:#000000;\">\n",
    "<p >Optimizers are algorithms used in deep learning to adjust the weights of a neural network during training in order to minimize the loss function. They guide the model towards better performance by determining how the model's parameters should be updated based on gradients calculated through backpropagation </p>\n",
    "<li>Gradient Descent</li>\n",
    "<li>Momentum</li>\n",
    "<li>AdaGrad</li>\n",
    "<li>RMS Prop</li>\n",
    "<li>Adam</li>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944aee68",
   "metadata": {
    "papermill": {
     "duration": 0.004445,
     "end_time": "2024-09-27T14:10:34.069987",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.065542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\"> Gradient Descent</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9c0b5",
   "metadata": {},
   "source": [
    "Gradient descent updates the weights based on the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a26f4",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\theta := \\theta - \\eta \\nabla_{\\theta} J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e97886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.080886Z",
     "iopub.status.busy": "2024-09-27T14:10:34.080434Z",
     "iopub.status.idle": "2024-09-27T14:10:34.092963Z",
     "shell.execute_reply": "2024-09-27T14:10:34.091983Z"
    },
    "papermill": {
     "duration": 0.020821,
     "end_time": "2024-09-27T14:10:34.095303",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.074482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self,learning_rate = 0.001):\n",
    "        self.learning_rate = learning_rate \n",
    "        \n",
    "    def update(self,weights,gradients):\n",
    "        weights = weights - self.learning_rate * gradients\n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850fd6d",
   "metadata": {
    "papermill": {
     "duration": 0.00437,
     "end_time": "2024-09-27T14:10:34.104267",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.099897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\">Stochastic Gradient Descent</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c00f38",
   "metadata": {},
   "source": [
    "\n",
    "SGD updates the weights based on a single training example at each iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853435a9",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\theta := \\theta - \\eta \\nabla_{\\theta} J(\\theta; x^{(i)}, y^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9075602c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.118188Z",
     "iopub.status.busy": "2024-09-27T14:10:34.117177Z",
     "iopub.status.idle": "2024-09-27T14:10:34.123702Z",
     "shell.execute_reply": "2024-09-27T14:10:34.122606Z"
    },
    "papermill": {
     "duration": 0.01552,
     "end_time": "2024-09-27T14:10:34.126413",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.110893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self,learning_rate = 0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def update(self,weights,gradients):\n",
    "        weights = weights - self.learning_rate * gradients\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bc8b5",
   "metadata": {
    "papermill": {
     "duration": 0.00458,
     "end_time": "2024-09-27T14:10:34.135665",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.131085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\">Momentum</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ee8b1",
   "metadata": {},
   "source": [
    "Momentum helps accelerate SGD by adding a fraction of the previous update to the current update.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f8501",
   "metadata": {},
   "source": [
    "$$\n",
    "v_t := \\beta v_{t-1} + (1 - \\beta) \\nabla_{\\theta} J(\\theta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\eta v_t \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a7aa30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.146393Z",
     "iopub.status.busy": "2024-09-27T14:10:34.145969Z",
     "iopub.status.idle": "2024-09-27T14:10:34.152666Z",
     "shell.execute_reply": "2024-09-27T14:10:34.151568Z"
    },
    "papermill": {
     "duration": 0.014923,
     "end_time": "2024-09-27T14:10:34.155067",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.140144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self,learning_rate=0.001,momentum= 0.9):\n",
    "        self.learning_rate = learning_rate \n",
    "        self.momentum = momentum\n",
    "        self.velocity = 0\n",
    "        \n",
    "    def update(self,weights,gradients):\n",
    "        self.velocity = self.momentum * self.velocity - self.learning_rate *self.gradient\n",
    "        weights = weigths+self.velocity\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416ce72",
   "metadata": {
    "papermill": {
     "duration": 0.004119,
     "end_time": "2024-09-27T14:10:34.163850",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.159731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\"> AdaGrad</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc535a7",
   "metadata": {},
   "source": [
    "\n",
    "Adagrad adapts the learning rate for each parameter based on the past gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00c48e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta := \\theta - \\frac{\\eta}{\\sqrt{G_{t,ii} + \\epsilon}} \\nabla_{\\theta} J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4d7791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.175005Z",
     "iopub.status.busy": "2024-09-27T14:10:34.174099Z",
     "iopub.status.idle": "2024-09-27T14:10:34.181225Z",
     "shell.execute_reply": "2024-09-27T14:10:34.180174Z"
    },
    "papermill": {
     "duration": 0.015206,
     "end_time": "2024-09-27T14:10:34.183511",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.168305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Adagrad:\n",
    "    def __init__(self,learning_rate = 0.001,epsilon = 1e-18):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.cache = 0\n",
    "        \n",
    "    def update (self,weights,gradients):\n",
    "        self.cache += gradients**2\n",
    "        weight_update = (self.learning_rate/ (np.sqrt(self.cache)+self.epsilon)) * gradients\n",
    "        weights -= weight_update\n",
    "        return weights\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a6453",
   "metadata": {
    "papermill": {
     "duration": 0.004112,
     "end_time": "2024-09-27T14:10:34.192049",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.187937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\"> RMS Prop</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d1d5",
   "metadata": {},
   "source": [
    "\n",
    "RMSProp scales the learning rate based on a moving average of the square of the gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78223a9d",
   "metadata": {},
   "source": [
    "$$\n",
    "E[g^2]t := \\beta E[g^2]{t-1} + (1 - \\beta) \\nabla_{\\theta} J(\\theta)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\frac{\\eta}{\\sqrt{E[g^2]t + \\epsilon}} \\nabla{\\theta} J(\\theta) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0caca186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.202819Z",
     "iopub.status.busy": "2024-09-27T14:10:34.202388Z",
     "iopub.status.idle": "2024-09-27T14:10:34.211202Z",
     "shell.execute_reply": "2024-09-27T14:10:34.209911Z"
    },
    "papermill": {
     "duration": 0.016929,
     "end_time": "2024-09-27T14:10:34.213603",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.196674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    def __init__(self,learning_rate = 0.0001,beta = 0.9,epsilon =1e-8):\n",
    "        self.learning_rate =learning_rate\n",
    "        self.beta = beta\n",
    "        self.epsion = epsilon\n",
    "        self.cache = cache\n",
    "        \n",
    "    def update(self,weights,gradients):\n",
    "        self.cache = self.beta * self.cache + (1-self.beta )* gradients ** 2\n",
    "        weight_update = (self.learning_rate*gradients) /(np.sqrt(self.cache)+self.epsilon)\n",
    "        weight -= weight_update\n",
    "        return weight\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7b56e",
   "metadata": {
    "papermill": {
     "duration": 0.004106,
     "end_time": "2024-09-27T14:10:34.222266",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.218160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <div style =\"font-size:25px; border-radius:25px; border:3666; padding:10px;  background-color:#fffafa; text-align:center; color:#000000;\"> Adam</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5cd3d6",
   "metadata": {},
   "source": [
    "Adam combines momentum and RMSProp, with separate moving averages for the gradients and squared gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5812468",
   "metadata": {},
   "source": [
    "$$\n",
    "m_t := \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_{\\theta} J(\\theta)\n",
    "$$\n",
    "$$\n",
    "v_t := \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla_{\\theta} J(\\theta))^2 ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{m}_t := \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t := \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "$$\n",
    "\\theta := \\theta - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229824e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-27T14:10:34.233196Z",
     "iopub.status.busy": "2024-09-27T14:10:34.232269Z",
     "iopub.status.idle": "2024-09-27T14:10:34.241609Z",
     "shell.execute_reply": "2024-09-27T14:10:34.240499Z"
    },
    "papermill": {
     "duration": 0.017344,
     "end_time": "2024-09-27T14:10:34.243961",
     "exception": false,
     "start_time": "2024-09-27T14:10:34.226617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self,learning_rate = 0.0001,beta1 = 0.9 , beta = 0.999,epsion = 1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "        self.m = 0\n",
    "        self.v = 0\n",
    "        self.t = 0\n",
    "        \n",
    "    def update(sself,weights,gradients):\n",
    "        self.t += 1\n",
    "        self.m = self.beta1 * self.m + (1-self.beta1)*gradients\n",
    "        self.v = self.beta2 * self.v + (1-self.beta2) * gradients\n",
    "        m_hat =self.m / (1-self.beta1 **self.t)\n",
    "        v_hat = self.v / ( 1- self.beta2 **self.t)\n",
    "        \n",
    "        weight_update = self.learning_rate * m_hat /(np.sqrt(v_hat) + self.epsilon)\n",
    "        weights = weighs - weight_update\n",
    "        return weights"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.359496,
   "end_time": "2024-09-27T14:10:34.568403",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-27T14:10:31.208907",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
