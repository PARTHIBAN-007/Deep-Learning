{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loss Functions\n","metadata":{}},{"cell_type":"markdown","source":"**Loss Functions are used to validate the model's predicted values and the actual values . By using the values of Loss functions the model's Performance is improved in Further iterations or epochs**\n\n**Loss functions are mostly classified into  2 types:**\n\nregression loss\n\nclassification loss\n\n\n**Major Loss Functions in Regression Loss:**\n\nMean Squared Errror\n\nMean Absolute Error\n\nHuber Loss\n\n**Major Loss Functions in Classification Loss:**\n\nlog loss Or binary cross-Entropy\n\ncategorical Cross Entropy\n\nSparse Categorical Cross Entropy\n","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:29.376740Z","iopub.execute_input":"2024-09-01T06:41:29.377227Z","iopub.status.idle":"2024-09-01T06:41:29.382907Z","shell.execute_reply.started":"2024-09-01T06:41:29.377187Z","shell.execute_reply":"2024-09-01T06:41:29.381438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Regression Loss","metadata":{}},{"cell_type":"markdown","source":"### Mean Squared Error","metadata":{}},{"cell_type":"code","source":"def mean_squared_error(y_true,y_pred):\n    return np.mean((y_true-y_pred )** 2)\ny_true = np.array([1,2,3])\ny_pred = np.array([1,2,5])\nmean_squared_error(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:29.511782Z","iopub.execute_input":"2024-09-01T06:41:29.512203Z","iopub.status.idle":"2024-09-01T06:41:29.521065Z","shell.execute_reply.started":"2024-09-01T06:41:29.512161Z","shell.execute_reply":"2024-09-01T06:41:29.519878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mean Absolute Error","metadata":{}},{"cell_type":"code","source":"def mean_absolute_error(y_true ,y_pred):\n    return np.mean(np.abs(y_true-y_pred))\ny_true = np.array([1,2,3])\ny_pred = np.array([1,2,5])\nmean_absolute_error(y_true,y_pred)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:29.563519Z","iopub.execute_input":"2024-09-01T06:41:29.564624Z","iopub.status.idle":"2024-09-01T06:41:29.572636Z","shell.execute_reply.started":"2024-09-01T06:41:29.564551Z","shell.execute_reply":"2024-09-01T06:41:29.571456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Huber Loss","metadata":{}},{"cell_type":"code","source":"def huber_loss(y_true ,y_pred,delta =1.0):\n    error = y_true -y_pred\n    threshold = np.abs(error)<=delta\n    squared_error =0.5 * np.square(error)\n    linear_error = delta * (np.abs(error) - 0.5 *delta)\n    return np.where(threshold,squared_error,linear_error).mean()\ny_true = np.array([1,2,3])\ny_pred = np.array([1,2,5])\nhuber_loss(y_true,y_pred)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:30.417621Z","iopub.execute_input":"2024-09-01T06:41:30.418720Z","iopub.status.idle":"2024-09-01T06:41:30.428210Z","shell.execute_reply.started":"2024-09-01T06:41:30.418670Z","shell.execute_reply":"2024-09-01T06:41:30.426966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Loss","metadata":{}},{"cell_type":"markdown","source":"### Binary Cross Entropy","metadata":{}},{"cell_type":"code","source":"def binary_cross_entropy(y_true ,y_pred):\n    y_pred = np.clip(y_pred , 1e-15 ,1-1e-15)\n    return -np.mean(y_true*np.log(y_pred) + (1-y_true)* np.log(1-y_pred))\ny_true = np.array([1,7,3])\ny_pred = np.array([1,2,5])\nbinary_cross_entropy(y_true,y_pred)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:30.552760Z","iopub.execute_input":"2024-09-01T06:41:30.553817Z","iopub.status.idle":"2024-09-01T06:41:30.563195Z","shell.execute_reply.started":"2024-09-01T06:41:30.553770Z","shell.execute_reply":"2024-09-01T06:41:30.561987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Cross Entropy","metadata":{}},{"cell_type":"code","source":"def categorical_cross_entropy(y_true ,y_pred):\n    y_pred = np.clip(y_pred , 1e-15,1-1e-15)\n    return -np.sum(y_true * np.log(y_pred))/y_true.shape[0]\ny_true= np.array([1,2,3])\ny_pred = np.array([1,2,5])\ncategorical_cross_entropy(y_true,y_pred)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:30.975615Z","iopub.execute_input":"2024-09-01T06:41:30.976716Z","iopub.status.idle":"2024-09-01T06:41:30.985977Z","shell.execute_reply.started":"2024-09-01T06:41:30.976654Z","shell.execute_reply":"2024-09-01T06:41:30.984900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sparse Categorical Cross Entropy","metadata":{}},{"cell_type":"code","source":"def sparse_categorical_cross_entropy(y_true,y_pred):\n    y_pred = np.clip(y_pred , 1e-15,1-1e-15)\n    log_prob = -np.log(y_pred[np.arange(len(y_true)),y_true])\n    return - np.mean(log_prob)\n\ny_true = np.array([1,0])\ny_pred = np.array([[0.1,0.9,0.0],[0.8,0.2,0.0]])\nsparse_categorical_cross_entropy(y_true,y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:31.080927Z","iopub.execute_input":"2024-09-01T06:41:31.081319Z","iopub.status.idle":"2024-09-01T06:41:31.090655Z","shell.execute_reply.started":"2024-09-01T06:41:31.081284Z","shell.execute_reply":"2024-09-01T06:41:31.089521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Huber Loss","metadata":{}},{"cell_type":"code","source":"def hinge_loss(y_true,y_pred):\n    return np.mean(np.maximum(0,1-y_true*y_pred))\ny_true = np.array([1,2,3])\ny_pred = np.array([1,2,5])\nhinge_loss(y_true,y_pred)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:41:31.092583Z","iopub.execute_input":"2024-09-01T06:41:31.092932Z","iopub.status.idle":"2024-09-01T06:41:31.108614Z","shell.execute_reply.started":"2024-09-01T06:41:31.092896Z","shell.execute_reply":"2024-09-01T06:41:31.107359Z"},"trusted":true},"execution_count":null,"outputs":[]}]}